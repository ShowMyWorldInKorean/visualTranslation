import os
import numpy as np
from paddleocr import PaddleOCR
from PIL import Image, ImageOps
import json
import re
from kor_ocr import save_all_ocr_results_to_txt

# PaddleOCR ì´ˆê¸°í™”
ocr = PaddleOCR(lang='korean', use_angle_cls=True, use_gpu=True)

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
IMAGE_PATH = r"E:\OCR\image"
GROUND_TRUTH_PATH = r"E:\OCR\correct"
OUTPUT_TXT_PATH = r"C:\Users\osh\visualTranslation\OCR\KOR_OCR\all_ocr_result.txt"

# OCR ì •ë‹µì—ì„œ "xxx" ì œê±°
def clean_ground_truth(text):
    return ' '.join([word for word in text.split() if word != "xxx"]).strip()

# ì •ë‹µ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë¡œë“œ
def load_ground_truth(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            annotations = data.get('annotations', [])
            texts = [annotation.get('text', '') for annotation in annotations]
            raw_text = ' '.join(texts).strip()
            return clean_ground_truth(raw_text)
    except Exception:
        return None

# ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ í° ë¬¸ì ì˜ì—­ ì¶”ì¶œ (ROI ì„ íƒ)
def extract_largest_text_region(image_path):
    try:
        with Image.open(image_path) as img:
            img = img.convert("L")  # í‘ë°± ë³€í™˜
            img = ImageOps.invert(img)  # ìƒ‰ìƒ ë°˜ì „ (í…ìŠ¤íŠ¸ ê°•ì¡°)
            img_array = np.array(img)

            # ì´ì§„í™”
            threshold = 128
            binary_img = np.where(img_array > threshold, 255, 0).astype(np.uint8)

            # ìœ¤ê³½ì„  ê²€ì¶œ
            non_zero_coords = np.column_stack(np.where(binary_img > 0))
            if non_zero_coords.shape[0] == 0:
                return img  # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜

            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x_min, y_min = non_zero_coords.min(axis=0)
            x_max, y_max = non_zero_coords.max(axis=0)

            # ROI ì¶”ì¶œ (ë¬¸ì ì˜ì—­ë§Œ ìë¥´ê¸°)
            return img.crop((y_min, x_min, y_max, x_max))
    except Exception:
        return None

# í‰ê°€ ì‹¤í–‰ (ì „ì²´ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ì— ëˆ„ì )
def evaluate_paddle_ocr(image_path, ground_truth_path):
    SUPPORTED_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')
    all_results = {}  # ëª¨ë“  ì´ë¯¸ì§€ì˜ ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬

    if not os.path.exists(image_path) or len(os.listdir(image_path)) == 0:
        print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return all_results

    for file in os.listdir(image_path):
        if file.lower().endswith(SUPPORTED_EXTENSIONS):
            try:
                image_file_path = os.path.join(image_path, file)
                json_file_path = os.path.join(ground_truth_path, os.path.splitext(file)[0] + '.json')

                if os.path.exists(json_file_path):
                    ground_truth = load_ground_truth(json_file_path)
                    if ground_truth is None:
                        continue
                else:
                    continue

                # ê°€ì¥ í° ë¬¸ì ì˜ì—­ ì¶”ì¶œ
                cropped_image = extract_largest_text_region(image_file_path)
                if cropped_image is None:
                    continue

                # OCR ì¸ì‹
                result = ocr.ocr(np.array(cropped_image), cls=True)
                if not result or not result[0]:
                    continue

                paddle_text = ' '.join([line[1][0] for line in result[0]]).strip()

                print(f"ğŸ“Œ íŒŒì¼: {file}")
                print(f"ğŸ” OCR ê²°ê³¼: {paddle_text}")
                print(f"âœ… OCR ì •ë‹µ: {ground_truth}\n")

                # ê° ê²€ì¶œ í•­ëª©ì„ all_resultsì— ì¶”ê°€
                for idx, detection in enumerate(result[0]):
                    try:
                        bbox_points = detection[0]  # 4ê°œì˜ ì  [[x,y], [x,y], [x,y], [x,y]]
                        xs = [point[0] for point in bbox_points]
                        ys = [point[1] for point in bbox_points]
                        # bboxë¥¼ í‰ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜: [min_x, min_y, max_x, max_y]
                        flat_bbox = [min(xs), min(ys), max(xs), max(ys)]
                        text = detection[1][0]
                        # í‚¤ ìƒì„±: íŒŒì¼ëª…(í™•ì¥ì ì œê±°)ì™€ ì¸ë±ìŠ¤ë¥¼ ì¡°í•©í•˜ì—¬ "ì‚¬ì§„ì´ë¦„_ë°•ìŠ¤ë²ˆí˜¸" í˜•ì‹ìœ¼ë¡œ ìƒì„±
                        key = f"{os.path.splitext(file)[0]}_{idx}"
                        all_results[key] = {"txt": text, "bbox": flat_bbox}
                    except Exception as e:
                        print(f"ê²€ì¶œ í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¸ë±ìŠ¤ {idx}): {e}")
                        continue

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

    return all_results

if __name__ == "__main__":
    results = evaluate_paddle_ocr(IMAGE_PATH, GROUND_TRUTH_PATH)
    if results:
        save_all_ocr_results_to_txt(results, OUTPUT_TXT_PATH)
