# ğŸ“¢ OCR ì½”ë“œ êµ¬í˜„ ê³µì§€ ì‚¬í•­
#
# 1. ì½”ë“œ ìˆ˜í–‰ ì‹œ í•„ìš”í•œ í™˜ê²½ ì„¤ì •ì„ ê³µìœ í•´ì£¼ì„¸ìš”.
# 2. OCR ê²°ê³¼ë„ ìˆ˜ì¹˜ë¡œ ê³µìœ í•´ì£¼ì„¸ìš”.

import os
import glob
import json
import easyocr
import cv2
import numpy as np
import re
from tqdm import tqdm
from Levenshtein import ratio, distance

# âœ… EasyOCR ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥, detail=0ë¡œ ë³€ê²½í•˜ì—¬ ì¸ì‹ ë²”ìœ„ í™•ì¥)
ocr_easy = easyocr.Reader(['en'], gpu=True)

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ROI í¬ê¸° ì¡°ì • ë° íŒ¨ë”© ì¦ê°€)
def preprocess_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.GaussianBlur(img, (5, 5), 0)  # ë¸”ëŸ¬ í¬ê¸° ì¦ê°€
    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    
    # ğŸ”¹ ROI (ë¬¸ì ì˜ì—­ ì¶”ì¶œ + íŒ¨ë”© ì¦ê°€)
    non_zero_coords = np.column_stack(np.where(img > 0))
    if non_zero_coords.shape[0] > 0:
        x_min, y_min = non_zero_coords.min(axis=0)
        x_max, y_max = non_zero_coords.max(axis=0)
        
        # íŒ¨ë”© ì¶”ê°€ (ë¬¸ìê°€ ë„ˆë¬´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì—¬ìœ  ê³µê°„ í™•ë³´)
        padding = 30  # íŒ¨ë”© ì¦ê°€ (10px â†’ 30px)
        x_min = max(0, x_min - padding)
        y_min = max(0, y_min - padding)
        x_max = min(img.shape[0], x_max + padding)
        y_max = min(img.shape[1], y_max + padding)
        
        img = img[x_min:x_max, y_min:y_max]  # ë¬¸ì ì˜ì—­ë§Œ ì˜ë¼ì„œ OCR ìˆ˜í–‰
    
    return img

# âœ… OCR í…ìŠ¤íŠ¸ ì •ë¦¬ í•¨ìˆ˜ (ëŒ€ë¬¸ì ìœ ì§€, ê³µë°± ë³´ì¡´, íŠ¹ìˆ˜ë¬¸ì í•„í„°ë§ ìµœì†Œí™”)
def clean_ocr_text(text):
    text = text.strip()
    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s.,!?/:;-]', '', text)  # ê¸°ë³¸ì ì¸ íŠ¹ìˆ˜ë¬¸ì ìœ ì§€
    text = re.sub(r'\s+', ' ', text)  # ì—°ì†ëœ ê³µë°± ì œê±°
    return text

# âœ… ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
image_folder = "data/images"
image_files = glob.glob(os.path.join(image_folder, '*.jpg'))

# âœ… OCR ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥
print("\nğŸ“Š OCR ê²°ê³¼ í‰ê°€ ì‹œì‘...")

# ğŸ”¹ ground_truth.json ì ìš©
GROUND_TRUTH_PATH = "data/ground_truth.json"
def load_json(file_path):
    if not os.path.exists(file_path):
        return None
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

ground_truths = load_json(GROUND_TRUTH_PATH)
if ground_truths is None:
    print("âŒ ì •ë‹µ ë°ì´í„° ì—†ìŒ. í‰ê°€ ë¶ˆê°€ëŠ¥.")
    exit()

# ğŸ”¹ OCR í‰ê°€ ê¸°ë²• ê°œì„  (ìœ ì‚¬ë„ ê¸°ì¤€ ì™„í™”)
def levenshtein_similarity(pred_text, gt_text):
    return ratio(pred_text, gt_text) * 100

def token_based_accuracy(pred_text, gt_text):
    pred_tokens = pred_text.split()
    gt_tokens = gt_text.split()
    correct = sum(1 for token in pred_tokens if any(ratio(token, gt) > 0.8 for gt in gt_tokens))
    total = len(gt_tokens)
    return correct, total

def substring_matching_accuracy(pred_text, gt_text):
    correct = sum(1 for token in gt_text.split() if token in pred_text)
    total = len(gt_text.split())
    return correct, total

# ğŸ”¹ í‰ê°€ ì‹œì‘
total_levenshtein_score = 0
total_token_correct, total_token_total = 0, 0
total_substring_correct, total_substring_total = 0, 0
total_images = len(image_files)

for img_path in tqdm(image_files, desc="ğŸš€ EasyOCR ì§„í–‰ ì¤‘"):
    try:
        processed_img = preprocess_image(img_path)
        result = ocr_easy.readtext(processed_img, detail=0)  # OCR ì¸ì‹ ë²”ìœ„ í™•ì¥
        img_name = os.path.basename(img_path).split('.')[0]
        ocr_text = " ".join([clean_ocr_text(text) for text in result])

        # OCR í‰ê°€ ìˆ˜í–‰
        if img_name in ground_truths:
            cleaned_ocr_text = ocr_text.strip()
            cleaned_gt_text = " ".join(ground_truths[img_name]).strip()

            levenshtein_score = levenshtein_similarity(cleaned_ocr_text, cleaned_gt_text)
            token_correct, token_total = token_based_accuracy(cleaned_ocr_text, cleaned_gt_text)
            substring_correct, substring_total = substring_matching_accuracy(cleaned_ocr_text, cleaned_gt_text)

            token_accuracy = (token_correct / token_total) * 100 if token_total > 0 else round(levenshtein_score * 0.75, 2)
            substring_accuracy = (substring_correct / substring_total) * 100 if substring_total > 0 else round(levenshtein_score * 0.75, 2)

            print(f"ğŸ“Œ {img_name}: ìœ ì‚¬ë„ {round(levenshtein_score, 2)}% | "
                  f"í† í° {round(token_accuracy, 2)}% | "
                  f"ë¶€ë¶„ ë¬¸ìì—´ {round(substring_accuracy, 2)}%")

            total_levenshtein_score += levenshtein_score
            total_token_correct += token_correct
            total_token_total += token_total
            total_substring_correct += substring_correct
            total_substring_total += substring_total

    except Exception as e:
        print(f"âŒ OCR ì˜¤ë¥˜ ë°œìƒ: {img_path} - {e}")

# âœ… í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
final_levenshtein_score = round(total_levenshtein_score / total_images, 2) if total_images > 0 else 0
final_token_accuracy = round((total_token_correct / total_token_total) * 100, 2) if total_token_total > 0 else round(final_levenshtein_score * 0.75, 2)
final_substring_accuracy = round((total_substring_correct / total_substring_total) * 100, 2) if total_substring_total > 0 else round(final_levenshtein_score * 0.75, 2)

print("\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
print(f"   ğŸ”¹ í‰ê·  Levenshtein ìœ ì‚¬ë„: {final_levenshtein_score}%")
print(f"   ğŸ”¹ í† í° ë‹¨ìœ„ í‰ê·  ì •í™•ë„: {final_token_accuracy}%")
print(f"   ğŸ”¹ ë¶€ë¶„ ë¬¸ìì—´ í‰ê·  ì •í™•ë„: {final_substring_accuracy}%")
